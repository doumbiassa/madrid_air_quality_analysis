{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# San Francisco Police Department Crime Rate Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project we will be analyzing Sa Francisco Police Department Crime Rate reports from [Kaggle](https://www.kaggle.com/psmavi104/san-francisco-crime-data). The data contains the \n",
    "\n",
    "* Incident_Datetime\n",
    "* Incident_Time\n",
    "* Incident_Year\n",
    "* Incident_Day_of_Week\n",
    "* Report_Datetime\n",
    "* Incident_ID\n",
    "* Row_ID\n",
    "* Incident_Number\n",
    "* CAD_Number\n",
    "* Report_Type_Code\n",
    "* Report_Type_Description\n",
    "* Filed_Online\n",
    "* Incident_Code\n",
    "* Incident_Category\n",
    "* Incident_Subcategory\n",
    "* Incident_Description\n",
    "* Resolution\n",
    "* Intersection\n",
    "* CNN\n",
    "* Police_District\n",
    "* Analysis_Neighborhood\n",
    "* Supervisor_District\n",
    "* Latitude \n",
    "* Longitude\n",
    "* point\n",
    "* SF_Find_Neighborhoods\n",
    "* Current_Police_Districts\n",
    "* Current_Supervisor_Districts\n",
    "* Analysis_Neighborhoods\n",
    "* HSOC_Zones_as_of_2018-06-05\n",
    "* OWED_Public_Spaces\n",
    "* Central_Market/Tenderloin_Boundary_Polygon_-_Updated\n",
    "* Parks_Alliance_CPSI_27+TL_sites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import some libraries **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing\n",
    "import warnings\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read in the csv file as a dataframe called df **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv('SFCD_2018.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = (10, 8)\n",
    "# plt.style.use('bmh')\n",
    "# wc = WordCloud(background_color = 'pink', width = 1500, height = 1500).generate(str(df['Incident_Description']))\n",
    "# plt.imshow(wc)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(),center =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df.drop(['CAD_Number', 'Report_Type_Code', 'Filed_Online', 'Incident_Code',\n",
    "       'Incident_Category', 'Incident_Subcategory', 'Intersection', 'CNN', 'Police_District',\n",
    "       'Analysis_Neighborhood', 'Supervisor_District',\n",
    "       'point', 'SF_Find_Neighborhoods', 'Current_Police_Districts',\n",
    "       'Current_Supervisor_Districts', 'Analysis_Neighborhoods',\n",
    "       'HSOC_Zones_as_of_2018-06-05', 'OWED_Public_Spaces',\n",
    "       'Central_Market/Tenderloin_Boundary_Polygon_-_Updated'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.dropna(how='all') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.Incident_Description.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = (10, 8)\n",
    "# plt.style.use('bmh')\n",
    "# wc = WordCloud(background_color = 'white', width = 1800, height = 1700).generate(str(df_2['Incident_Description']))\n",
    "# plt.imshow(wc)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_2.corr(),center =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['Incident_Datetime'] = pd.to_datetime(df_2['Incident_Datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['date'] = df_2['Incident_Datetime'].apply(lambda t: t.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['month'] = df_2['Incident_Datetime'].apply(lambda time: time.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['hour'] = df_2['Incident_Datetime'].apply(lambda time: time.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['day'] = df_2['Incident_Datetime'].apply(lambda time: time.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.drop(['Incident_Date', 'Incident_Time', 'Incident_Year','Row_ID', 'Incident_ID', 'Report_Type_Description', 'Parks_Alliance_CPSI_27+TL_sites','Incident_Number', 'Report_Datetime','Incident_Datetime'], axis  = 1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** What are the top 20 crimes in San Francisco? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.Incident_Description.value_counts().head(20).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_2.groupby('Incident_Description')['Longitude'].value_counts().plot()\n",
    "plt.title('Reasons')\n",
    "plt.figure(figsize=(20, 6))\n",
    "#plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.countplot(x='month',data=byMonth,hue='Incident_Description',palette='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byMonth = df_2.groupby('Incident_Day_of_Week').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byMonth['Incident_Description'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.Resolution.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "crimes=list(df_2.Incident_Description.values)\n",
    "key_crimes = []\n",
    "for x in crimes:\n",
    "    crime = x.split()\n",
    "    for c in crime:\n",
    "        key_crimes.append(c.strip(','))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_df = pd.DataFrame(key_crimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_df[0].value_counts(normalize = True).head(75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_cr = ['Larceny','Theft', 'Assault', 'Vandalism', 'Burglary',\n",
    "          'Battery','Rape','Possession', 'Robbery','Fraudulent','Mental','Violation','Person',\n",
    "         'Suspicious','Shoplifting','Traffic','Vehicle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_crime(x):\n",
    "    cr = 'general'\n",
    "    for crime in key_cr:\n",
    "        if crime in x:\n",
    "            cr = crime\n",
    "    return cr\n",
    "df_2['Crime'] = df_2.Incident_Description.apply(assign_crime)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_2[df_2.Crime != 'general']\n",
    "df_3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_pd = pd.concat([df_3,pd.get_dummies(df_3.Crime)],axis = 1)\n",
    "crimes_pd = pd.concat([crimes_pd,pd.get_dummies(crimes_pd.Incident_Day_of_Week)],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_pd.drop(['Incident_Description','date','Incident_Day_of_Week','Crime'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_pd.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = crimes_pd.drop('Resolution', axis = 1)\n",
    "y = crimes_pd.Resolution\n",
    "X_train, X_test,y_train,y_test = train_test_split(X,y,test_size = .3, random_state = 212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor,AdaBoostClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test,y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ROCAUC\n",
    "from yellowbrick.classifier import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ROCAUC(clf)\n",
    "\n",
    "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "\n",
    "visualizer.poof()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(clf)\n",
    "\n",
    "# To create the ConfusionMatrix, we need some test data. Score runs predict() on the data\n",
    "# and then creates the confusion_matrix from scikit-learn.\n",
    "cm.score(X_test, y_test)\n",
    "\n",
    "# How did we do?\n",
    "cm.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RF_weights = RandomForestClassifier(n_jobs=-1,class_weight={'Open or Active':0.81,\n",
    "                                                      'Cite or Arrest Adult':0.17,\n",
    "                                                     'Cite or Arrest Juvenile': .006,\n",
    "                                                     \"Unfounded\":0.004648,\n",
    "                                                     \"Exceptional Adult\":0.001451,\n",
    "                                                    \"Exceptional Juvenile\":0.000249},\n",
    "                                        max_depth = 1000, random_state = 24,n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RF_weights.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = clf_RF_weights.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_hat) * 100\n",
    "print(f\"Accuracy Score is {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ROCAUC(clf_RF_weights)\n",
    "\n",
    "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "\n",
    "visualizer.poof()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(clf_RF_weights)\n",
    "\n",
    "# To create the ConfusionMatrix, we need some test data. Score runs predict() on the data\n",
    "# and then creates the confusion_matrix from scikit-learn.\n",
    "cm.score(X_test, y_test)\n",
    "\n",
    "# How did we do?\n",
    "cm.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_pd.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_pd.to_csv(\"data/crime_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = crimes_pd.drop('Resolution', axis = 1)\n",
    "y = crimes_pd.Resolution\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_Fold_Classification(X,y,n):\n",
    "    kf = KFold(n_splits=n)\n",
    "    kf.get_n_splits(X)\n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        clf_RF_weights.fit(X_train,y_train)\n",
    "        y_hat = clf_RF_weights.predict(X_test)\n",
    "        y_hat_train = clf_RF_weights.predict(X_train)\n",
    "        acc = accuracy_score(y_test, y_hat) * 100\n",
    "        acc_train = accuracy_score(y_train, y_hat_train) * 100\n",
    "        train_score.append(acc_train)\n",
    "        test_score.append(acc)\n",
    "    return train_score,test_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = K_Fold_Classification(X,y,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# xs = list(range(1, 6))\n",
    "# figure = plt.figure(figsize=(10, 6)) # first element is width, second is height.\n",
    "# axes = figure.add_subplot(1, 1, 1)\n",
    "\n",
    "# axes.plot(xs, test, color=\"firebrick\")\n",
    "# axes.plot(xs, train, color=\"cornflowerblue\")\n",
    "\n",
    "# axes.set_xticks(xs)\n",
    "# axes.set_xticklabels([str(x) for x in xs])\n",
    "\n",
    "# axes.set_title(\"Validation Curves\")\n",
    "# axes.set_xlabel(\"k\")\n",
    "# axes.set_ylabel(\"Accuracy\")\n",
    "\n",
    "# plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC  \n",
    "svclassifier = SVC(kernel='linear')  \n",
    "svclassifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix , accuracy_score\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) \n",
    "print(f\"The accuracy score is {accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_GS = RandomForestClassifier(n_jobs=-1,\n",
    "                                class_weight={'Open or Active':0.81,\n",
    "                                             'Cite or Arrest Adult':0.17,\n",
    "                                             'Cite or Arrest Juvenile':0.006,\n",
    "                                             \"Unfounded\":0.004648,\n",
    "                                             \"Exceptional Adult\":0.001451,\n",
    "                                             \"Exceptional Juvenile\":0.000249},\n",
    "                                random_state = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CV_rfc = GridSearchCV(estimator=clf_GS, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_rfc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "** Split your data into a training set and a testing set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = crimes_pd.drop('Resolution',axis=1)\n",
    "y = crimes_pd['Resolution']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_pd['Resolution'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Model\n",
    "\n",
    "Now its time to train a Support Vector Machine Classifier. \n",
    "\n",
    "**Call the SVC() model from sklearn and fit the model to the training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC()\n",
    "svc_model = SVC(kernel='linear') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "**Now get predictions from the model and create a confusion matrix and a classification report.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix , accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch Practice\n",
    "\n",
    "** Import GridsearchCV from SciKit Learn.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a dictionary called param_grid and fill out some parameters for C and gamma.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001]} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a GridSearchCV object and fit it to the training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Now take that grid model and create some predictions using the test set and create classification reports and confusion matrices for them. Were you able to improve?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
